\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{dsfont}
\usepackage{amsmath}
\usepackage{nccmath}
\usepackage{scrextend}
\usepackage{amssymb}
\usepackage{multirow,array}
\usepackage[margin=1.5in]{geometry}
\usepackage{color,soul}
\begin{document}
\centering
\Large

\pagebreak

Forthcoming:

\textbf{Theorem 2.} Define G to be a 2x2 coordination game and let $P^{m,s,\epsilon}$ be adaptive learning with memory $m$, sample size $s$, and error rate $\epsilon$. For all sufficiently large $m$ (2?) the stochastically stable states of the perturbed process corresponds 1 to 1 with the risk dominant conventions.

\vskip12pt

\textbf{Theorem 3.} Define G to be a $K$x$K$ coordination game and let $P^{m,s,\epsilon}$ be adaptive learning with memory $m$, sample size $s$, and error rate $\epsilon$. Let $(k,k)$ be Nash Equilibria for all $k \in \{1,...,K\}$. Define $i \in \{1,...,K\}$ and $j \neq i \in \{1,...,K\}$ to be conventions of both players playing action $i$ in convention $i$ and both players playing action $j$ in convention $j$.

\textit{1.} For all $s, m$ the resistance from state $i$ to state $j$ is:

$$r(i,j)=\min(\lceil \alpha s \rceil,\lceil \beta s \rceil)+\max(\lceil \alpha s \rceil+\lceil \beta s \rceil-m,0)$$

\textit{2.} The risk dominance relation between state $i$ and $j$ remains unchanged for all $s/m \in (0,1]$ when $m$ is sufficiently large.

\textit{3.} In some, but not all, larger games (at least 3x3) which states are stochastically stable may depend on $s/m \in (0,1]$. If so, the value of $s/m \in (0,1]$ at which stochastic stability changes can be easily calculated.

%better to have higher s/m or lower?




\end{document}

