\documentclass[11.5pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{multirow}
\usepackage{fullpage}
\usepackage{subfigure}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{color}
\usepackage{cases}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{float}
\usepackage{natbib}
\usepackage{array}
\usepackage{booktabs}
\usepackage{caption}
\usepackage[english]{babel}
\usepackage{ragged2e}
\usepackage{blindtext}
\usepackage[unicode=true, bookmarks=true, bookmarksnumbered=false, bookmarksopen=false, breaklinks=true, pdfborder={0 0 0},backref=false]{hyperref}
\hypersetup{
  colorlinks=true,
  allcolors=blue
}

\doublespacing

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Minimally Incomplete Information and Convergence of Adaptive Play in $2\times 2$ Games}


\author{Ethan Holdahl\thanks{University of Oregon} \and Anne van den Nouweland\thanks{Department of Economics, University of Oregon, Eugene, OR 97403-1285. Email: annev@uoregon.edu.}}



\begin{document}

\maketitle 

\begin{abstract}

\noindent \textbf{Keywords:}\\
\noindent \textbf{JEL Classification Codes: } \\

\end{abstract}



%\justifying
%
\newpage

\section{Introduction}
With over 1000 citations, \cite{young1993evolution} is a seminal paper in the field of evolutionary game theory. In it, Young introduces a model of learning called adaptive play in which players best respond to a sampled history of play. Young proved that play will eventually converge to a convention, a self-enforcing pattern of play where the same Nash equilibrium is played in each period, if the sampling in the available history by the players is sufficiently incomplete. Through this backward looking best response behavior, Young offers an explanation for how order and norms can spontaneously evolve in populations.

In the process of adaptive play, occasionally players make mistakes and play an action that is not a best response. Such instances are called perturbations and allow the perturbed adaptive play process to escape a convention and travel to another one. The resistance of moving from one convention to another is measured by the number of mistakes that are necessary to move the process into the basin of attraction of the latter convention. The conventions that require the most mistakes to move from and/or the fewest to move to are most likely to be played in the long run. Such conventions are said to be stochastically stable. The theory of adaptive play, sometimes called adaptive learning or fictitious play with bounded memory, and its most celebrated result, identifying the 
stochastically stable patterns of play, have since been applied to a wide variety of games. We restrict the scope of our literature review here to games with finitely many strategies 
in which groups of players interact with each other on a random basis.\footnote{So, we do not, for example, consider games played on networks. For an introduction and references to the extensive  literature on such games, we refer to reader to \cite{WALLACE2015327}.
}

In his book \emph{Individual Strategy and Social Structure} (\cite{Young1998}),
 Young expanded upon the foundation he laid in \cite{young1993evolution}. He proved that in 
$2\times 2$ coordination games adaptive play eventually converges to a convention if the amount sampled ($s$) in the available memory ($m$) is sufficiently incomplete, where the criterion for "sufficiently" incomplete is slackened to $s/m \leq 1/2$ in \cite{Young1998} (from the more permissive restriction in \cite{young1993evolution}\footnote{The result in \cite{young1993evolution} that we are referring to is Theorem 1, which is formulated for a more general setting than only $2\times 2$ coordination games.}). 
%
Most recently, Proposition 6.4 of \cite{WALLACE2015327} simply states that in n-player coordination games "if s/m is sufficiently small, the [adaptive learning] process converges with probability one to a convention from any initial state". 
Although acknowledged by Young in his 1998 book, "We do not claim the bound on incompleteness $s/m \leq 1/2$ is the best possible", to our knowledge no one has found and proven what the best possible bound is. Consequently, follow-up work building upon this theory has retained the restrictive bound of $s/m \leq 1/2$. 

The literature we review applies adaptive learning to a variety of games with a focus on finding different criteria for stochastic stability. \cite{maruta1997relationship} and \cite{ellison2000basins} independently introduced the idea of global risk dominance,\footnote{The terminology "global risk dominance" was introduced in \cite{maruta1997relationship}.}  which indicates the existence of an action that risk dominates every other strategy in a game, and showed that the stochastic adaptive learning process of \cite{young1993evolution} selects the globally risk dominant strategy if there is one.

\cite{durieu2011adaptive} applied Young's adaptive play model to the concept of $p$-best response sets. 
The idea of $p$-dominant equilibrium, first introduced by \cite{morris1995p}, was adapted by \cite{tercieux2006p} to create the concept of $p$-best response sets.
A $p$-best response set is a cartesian product of strategies for each player such that when all players believe all other player(s) will play a strategy contributing to the $p$-best response set with at least probability $p$ then the best response(s) of all players are strategies contributing to the $p$-best response set.
A $p$-best response set with $p=1$ is therefore equivalent to the concept of a so-called curb set as introduced by \cite{basu1991strategy} and discussed in the context of adaptive play in Chapter 7 of \cite{Young1998}. 
A $p$-best response set is said to be minimal if it contains no proper subsets which are also $p$-best response sets.  \cite{durieu2011adaptive} show that in n-person games, if $p$ is sufficiently small then there is a unique minimal $p$-best response set and only the strategy profiles contained within the 
unique minimal $p$-best response set can be stochastically stable given perturbation rates are also sufficiently small.
Note that this method does not necessarily make as sharp a prediction as \cite{young1993evolution} since a $p$-best response set may contain multiple conventions of which not all are stochastically stable.

Breaking off from the canonical model, adaptive play has also been modified to fit a cognitive hierarchy framework \citep{saez1999clever, matros2003clever, khan2014cognitive}. This branch of theory allows for variability in the degree of sophistication through which players compute their best response, similar to level-k thinking as introduced by \cite{nagel1995unraveling}. In Young's model of adaptive play, agents are backwards looking and best respond to their sample of their opponents' play. \cite{saez1999clever} and \cite{matros2003clever} refer to these players as "not clever" and \cite{khan2014cognitive} refers to them as "level-1" individuals. One step higher on the cognitive scale are the "clever" and "level-2" individuals. These players sample their own history of play, compute their 
opponents' best responses to that, and then play their own best response to their opponents' predicted play. 
\cite{saez1999clever} and \cite{matros2003clever} cap the cognitive hierarchy at level-2 whereas \cite{khan2014cognitive} allows higher levels and moreover has even-leveled individuals sample their own history and odd-leveled individuals sample their opponents' history. 
\cite{saez1999clever} studies bargaining games, \cite{matros2003clever} studies generic two-player games, and \cite{khan2014cognitive} covers both of these. All three impose $s \leq m/2$\footnote{The authors allow for different roles in the game to have different sample sizes but impose the upper limit of $m/2$ for all samples.} and find that introducing "clever" agents can change which states are stochastically stable. \cite{matros2003clever} and \cite{khan2014cognitive} find that play with "clever" agents still converges to a minimal curb set.

\cite{jensen2005evolution} applies adaptive play to static $2$-player games of incomplete information. They allow for different types of players within the class of players for each role in the game, where  each type of player creates their own history. In each period, only the memories of the types who are selected to play are updated, and those of the other types remain unchanged. Players know the distribution of types in the other classes and sample for each type from the most recent $m$ periods in which that type played, and then weight their sample by the prevalence of each type and subsequently compute their best response. 
\cite{jensen2005evolution} examines in detail a $2\times 2$ game of chicken with incomplete information and leverages the condition $s<m/4$ (which they obtain by applying Theorem 1 in  \cite{young1993evolution})
to show that the basic learning process converges to a convention and that convention may be one which "lacks coordination" where not all types for the same player play the same strategy. Depending on the payoffs in the game, this "uncoordinated" convention can be stochastically stable. 

In our paper we show that \textit{any} degree of incomplete sampling is sufficient for the unperturbed adaptive play process to converge to an equilibrium in $2\times 2$ coordination games from any given history. In addition, we show that incomplete information is unnecessary in all but some $2 \times 2$ games. We also show that increasing the sample size beyond $s/m \leq 1/2$ may result in increased levels of resistance between conventions, that is to say, increasing the sample size may make conventions more stable. However, even though the resistance between conventions may change, we show that this change does not affect which convention(s) are stochastically stable when sampling is incomplete ($s<m$).

\section{Adaptive play in $2\times 2$ coordination games}

\subsection{$2\times 2$ coordination games}

Consider a $2\times 2$ game $G=(N;A_1,A_2;u_1, u_2)$ with player set $N=\{1,2\}$, actions sets $A_1=\{a_1,a_2\}$ and $A_2=\{b_1,b_2\}$, and payoff functions $u_i: A_1\times A_2 \rightarrow \bf{R}$ ($i=1,2$). The game $G$ is a coordination game if it has two pure-strategy Nash equilibria on a diagonal. Without loss of generality, we assume that $(a_1,b_1)$ and $(a_2,b_2)$ are Nash equilibria and we also assume that for player 1 either $u_1(a_1,b_1) > u_1(a_2,b_1)$ or $u_1(a_2,b_2) > u_1(a_1,b_2)$ and for player 2 either $u_2(a_1,b_1) > u_2(a_1,b_2)$ or $u_2(a_2,b_2) > u_2(a_2,b_1)$. These last two conditions rule out the possibility that one of the players has the same payoff from both their actions regardless of the action played by the other player, in which case the only distinction between a player's two actions is, from their own perspective, the names of the actions. %and the player arguably strategically has only one action to their disposal and the game is not really a $2\times 2$ game. 

Because each player has only two actions in the game $G$, every mixed strategy $p_i$ of player $i\in \{1,2\}$ can be identified by the probability $p_i(s_i)$ with which player~$i$ plays one of their actions~$s_i$ (because that leaves probability $1-p_i(s_i)$ that player~$i$ plays their other action). 
%
Action $a_1$ is a best response by player~$1$ to a mixed strategy $p_2$ of player~$2$ if and only if 
$p_2(b_1) \geq \frac{u_1(a_2,b_2)-u_1(a_1,b_2)}{u_1(a_1,b_1)-u_1(a_1,b_2)-u_1(a_2,b_1)+u_1(a_2,b_2)}.$ Note that $\alpha_2 :=\frac{u_1(a_2,b_2)-u_1(a_1,b_2)}{u_1(a_1,b_1)-u_1(a_1,b_2)-u_1(a_2,b_1)+u_1(a_2,b_2)}\in [0,1]$ because $G$ is a coordination game with Nash equilibria $(a_1,b_1)$ and $(a_2,b_2)$, and either $u_1(a_1,b_1) > u_1(a_2,b_1)$ or $u_1(a_2,b_2) > u_1(a_1,b_2)$.\footnote{The only possible hick-up is that the denominator could equal 0, but that is ruled out when player~$1$ has two actions that differ to them in more than name only.}
%
Similarly, action $b_1$ is a best response by player~$2$ to a mixed strategy $p_1$ of player~$1$ if and only if 
$p_1(a_1) \geq \alpha_1 := \frac{u_2(a_2,b_2)-u_2(a_2,b_1)}{u_2(a_1,b_1)-u_2(a_2,b_1)-u_2(a_1,b_2)+u_2(a_2,b_2)} \in [0,1]$.


\subsection{Adaptive play in 2-player games}
 
We study adaptive play \citep{young1993evolution} with memory $m$ and sample size $1<k\leq m$ of the game~$G$, as explained below.\footnote{Throughout, we use $k$ for the sample size because we already use $s$ for strategies.} 
Anne: I added a footnote.

For each role (player position)~$i\in N$ in game~$G$, there is a class of players $C_i$ who can play that role. No player can play in more than one role ($C_1\cap C_2=\emptyset$). 
In each period $t$, a player is drawn from each class, and the two players that are drawn play the game $G$ -- each player~$i$ chooses an action $s_i(t)\in A_i$ from the actions available to them in their role. 
The action-tuple $s(t) = (s_1(t), s_2(t))$ is recorded and will be referred to as the play at time $t$. 
The history of plays up to and including time $t$ is the ordered vector $h(t) = (s(1), s(2), s(3), ..., s(t))$, and the history of the last $m$ plays, called a state, is the ordered vector $h(t\mid m) = (s(t-m+1), s(t-m+2), ..., s(t))$.

In period $t+1$, the player in role~$i$ draws a sample $R_i^{t+1}$ of size $k$ from the $m$ most recent plays $s_j(t-m+1), s_j(t-m+2), \ldots, s_j(t)$ by the players in role~$j\neq i$. 
Player~$i$ predicts that the players in role~$j$ play a mixed strategy $p_j(\cdot | R_i^{t+1})$ that is the frequency distribution of the actions in the sample drawn: $p_j(s_j | R_i^{t+1})$ equals the number of times that action $s_j$ occurs in the sample $R_i^{t+1}$ divided by $k$, for each $s_j\in A_j$. 
%
Player~$i$ then plays an action that is a best response to this predicted mixed strategy:  
$s_i(t+1)\in BR_i(R_i^{t+1}):=\arg\max \,\{ \sum_{s_j\in A_j} \left( p_j(s_j | R_i^{t+1})\cdot u_i(s_i,s_j) \right) \mid s_i\in A_i \} .$




\bigskip

The decision making process described above is called unperturbed adaptive play with memory size $m$ and sample size $k$. Through an adaptive play process, self-enforcing patterns of play, called conventions, can emerge.


\begin{definition}
A {\emph{convention}} is a state $h(t\mid m)$ that entirely consists of $m$ repetitions of the same Nash equilibrium $s^*$ of the game~$G$.
\end{definition}

When a convention is reached in which the Nash equilibrium $s^*$ is played, then the players can only sample the others playing their part of $s^*$ and thus all players have a best response to play their part of~$s^*$. That means that adaptive play predicts that the players can keep playing $s^*$ in all subsequent periods. If the Nash equilibrium $s^*$ is strict, then the best responses are unique and, without perturbations, the players will keep playing $s^*$ indefinitely. 


%Consider a game $G=(N;\{A_i\}_{i\in N};\{u_i\}_{i\in N})$ with player set $N=\{1,2,\ldots, n\}$ in which each player~$i$ has a set of possible actions~$A_i$ and payoff function $u_i$ that assigns a payoff to player~$i$ for each action profile $a=(a_j)_{j\in N}$. We study adaptive play \citep{Young19??} with memory $m$ and sample size $1<k\leq m$ of the game~$G$, as explained below.
%
%For each role (player position)~$i\in N$ in game~$G$, there is a class of players $C_i$ who can play that role. No player can play in more than one role ($C_i\cap C_j=\emptyset$ for all $i,j\in N$, $i\neq j$). 
%In each period $t$, a player is drawn from each class, and the $|N|$ players that are drawn play the game $G$ -- each player~$i$ chooses an action $s_i(t)\in A_i$ from the actions available to them in their role. 
%The action-tuple $s(t) = (s_1(t), ..., s_n(t))$ is recorded and will be referred to as the play at time $t$. 
%The history of plays up to and including time $t$ is the ordered vector $h(t) = (s(1), s(2), s(3), ..., s(t))$.
%
%In period $t+1$, the player in role~$i$ draws for each other role $j\in N\setminus \{i\}$ a sample $R_i^{t+1}(j)$ of size $k$ from the $m$ most recent plays $s_j(t-m+1), s_j(t-m+2), \ldots, s_j(t)$ by the players in role~$j$. 
%Player~$i$ predicts that the players in role~$j$ play a mixed strategy $p_i^{t+1}(j)$ that is the frequency distribution of the actions in the sample drawn: $p_i^{t+1}(j)(a_j)$ equals the number of times that action $a_j$ occurs in the sample $R_i^{t+1}(j)$ divided by $k$, for each $a_j\in A_j$. 
%
%We denote player $i$'s ordered collection of $n-1$ samples in period $t+1$ by $R_i^{t+1}$ and player $i$'s best responses to the predicted mixed strategies of the other players by $BR_i(R_i^{t+1})$. 
%Thus, $BR_i(R_i^{t+1})=\arg\max \{  \} .$
%
%Player~$i$ predicts that the other players play according to a mixed strategy equal to frequency distribution in their sample, with probabilities $p(s_{-i})=\Pi_{j\in N\setminus \{i\}} p(s_j\mid R_i^{t+1})$
%
%After having drawn their samples, player~$i$ plays an action $s_i(t+1)$ that is a best response to their sampled distribution of the other players' strategies, $s_i(t+1) \in \{BR_i(R_i^{t+1})\}$. A player's best response function selects the set of strategies that maximize their payoffs, $BR_i(R_i^{t+1}) = \max\limits_{\{s_i\}}  \sum\limits_{s_{-i} \in S_{-i}} \pi_i(s_i,s_{-i}) p(s_{-i}|R_i^{t+1})$ where $\pi_i(s_i,s_{-i})$ is the payoff player $i$ gets when they play $s_i$ and the other players collectively play $s_{-i}$, and $p(s_{-i}|R_i^{t+1}) = \prod\limits_{s_j \in s_{-i}} p(s_j|R_i^{t+1})$ is the probability that each player other that player $i$ plays their strategy $s_j$ in $s_{-i}$, assuming players choose their strategies independently of one another.
%
%
%
%
%The players play best responses to their predicted mixed strategies by the players in the other roles, and predictions are generated through sampling: The player in role~$i$ draws for each other role $j\in N\setminus \{i\}$ a sample $R_i^t(j)$ of size $k$ from the most recent $m$ records $s_j(t-m), s_j(t-m+1), \ldots, s_j(t-1)$ of play by the players in role~$j$, and predicts that the players in role~$j$ play a mixed strategy that is the frequency distribution of the actions in the sample drawn. Thus, based on $|N|-1$ independent samples $R_i^t=(R_i^t(j))_{j\in N\setminus \{i\}}$ drawn, player~$i$ obtains a prediction of a mixed strategy profile that is played by all other players and plays a best response to that; $s_i(t)\in BR_i(R_i^t)$. 
%
%
%
%The decision making process described above is called unperturbed adaptive play with memory size $m$ and sample size $k$. Though an adaptive play process, self enforcing patterns of play, called conventions, can emerge.



\section{Minimally incomplete information} 



In \cite{Young1998}, Young proved that in $2\times 2$ coordination games, unperturbed adaptive play will reach a convention as long as information is sufficiently incomplete. Incomplete information means that the players sample only a faction of the information in memory and in \cite{Young1998} the specific limit for information to be "sufficiently" incomplete is $k \leq \frac{m}{2}$, meaning that players sample at most half of all the information available in memory. 
We relax this bound substantially and show that in $2\times 2$ coordination games, {\emph {any} }degree of incomplete information is sufficient for a convention to eventually be reached.




%\justifying

Lemma~\ref{Lemma_1} will be used in the proof of Theorems~\ref{Theorem_1} and \ref{Theorem_2}.

\vskip12pt


%\noindent ********************************************************************


\begin{lemma}\label{Lemma_1} Let G be a 2$\times$2 coordination game and let $s^* = (s^*_1, s^*_2)$ be a (pure-strategy) Nash equilibrium of $G$. Consider unperturbed adaptive play with memory size $m$ and sample size $k\leq m$. Let $t > m$ be a period in which each player~$i\in\{1,2\}$ can play $s^*_i$ as a best response to their sampled history, so that there is a positive probability that the strategy-tuple $s^*$ is played in period~$t$. Then the convention of playing $s^*$ can be reached with positive probability.
\end{lemma}



\textbf{Proof of Lemma~\ref{Lemma_1}.} 
%Because each player has only two actions in the game $G$, every mixed strategy $p_i$ of player $i\in \{1,2\}$ can be identified by the probability $p_i(s_i^*)$ with which player~$i$ plays action~$s_i^*$ (because that leaves probability $1-p_i(s_i^*)$ that player~$i$ plays their other action, which we will denote by $s_i'$). 
%In addition, action $s_i^*$ is a best response by player~$i$ to a mixed strategy $p_j$ of player~$j$ if and only if 
%$p_j(s_j^*) \geq \frac{u_i(s_i',s_j')-u_i(s_i^*,s_j')}{u_i(s_i^*,s_j^*)-u_i(s_i^*,s_j')-u_i(s_i',s_j^*)+u_i(s_i',s_j')}.$\footnote{Note that $\frac{u_i(s_i',s_j')-u_i(s_i^*,s_j')}{u_i(s_i^*,s_j^*)-u_i(s_i^*,s_j')-u_i(s_i',s_j^*)+u_i(s_i',s_j')}\in [0,1)$ because $G$ is a coordination game with Nash equilibria $(s_i^*,s_j^*)$ and $(s_i',s_j')$ and the Nash equilibrium $(s_i^*,s_j^*)$ is strict. The only possible hick-up here is that the denominator could equal 0, but that only happens when player~$i$ has the same payoff from both their actions for both actions of player~$j$, in which case the only distinction between player~$i$'s two actions is the names of the actions and player~$i$ arguably strategically has only one action to their disposal.}
%
%
%
%\medskip
Using induction, we show that there exists a positive probability that $s^*$ is played in periods $t$ through $t+m-1$, so that the convention of playing $s^*$ is reached.

\textit{Base Step:} By assumption, the strategy-tuple $s^* = (s^*_1, s^*_2)$ is played with positive probability in period~$t$.



\textit{Inductive Step:} Let $\hat{t}\geq t$ and suppose that it has already been demonstrated that each player~$i\in\{1,2\}$ can play $s^*_i$ as a best response to their sampled history in period $\hat{t}$, so that there is a positive probability that the strategy-tuple $s^*$ is played in period~$\hat{t}$. It will be shown that there is a positive probability that $s^*$ is played in period~$\hat{t}+1$ as part of adaptive play. 

\vskip6pt

For each player $i\in \{1,2\}$, let $R_i^{\hat{t}}$ be a sampled history of player~$i$ in period~$\hat{t}$ such that $s^*_i\in BR_i(R_i^{\hat{t}})$, and let $s_i(\hat{t})=s_i^*$. Then there is a positive probability that each player~$i$ draws a sample $R_i^{\hat{t}+1}$ that is obtained by replacing one of the records in $R_i^{\hat{t}}$ with $s_j(\hat{t})=s_j^*$ ($j\neq i$). If the replaced record is equal to $s_j^*$, then this does not change the frequency of $s_j^*$ in~$i$'s sample, and if the replaced record is not equal to $s_j^*$, then this increases the frequency of $s_j^*$ in~$i$'s sample. 
If $s^* =(a_1,b_1)$, then $p_j(s_j^* | R_i^{\hat{t}+1})\geq p_j(s_j^* | R_i^{\hat{t}})\geq \alpha_j,$ where the last step holds because $s^*_i\in BR_i(R_i^{\hat{t}})$. 
Similarly, if $s^* =(a_2,b_2)$, then $p_j(s_j^* | R_i^{\hat{t}+1})\geq p_j(s_j^* | R_i^{\hat{t}})\geq 1-\alpha_j.$ 
In both cases,  it follows that $s^*_i\in BR_i(R_i^{\hat{t}+1})$.%\footnote{Note that this step depends crucially on the fact that player~$j$ has only two actions. See the remark directly following this lemma for an example that demonstrates what may go wrong if players have more than two actions.}

Therefore, there is a positive probability that $s^*$ is played in period~$\hat{t}+1$ as part of adaptive play. 

\medskip
\textit{Conclusion:} Using the inductive step $m-1$ times, it has thus been shown that there exists a positive probability that $s^*$ is played in periods $t$ through $t+m-1$, so that the convention of playing $s^*$ is reached.
$\blacksquare$



%\vskip18pt
\bigskip

Lemma~\ref{Lemma_1} exploits the fact that in a $2\times 2$ game, when player~$i$'s Nash equilibrium action $s_i^*$ is a best response to the other player~$j$'s mixed strategy, and subsequently, the probability that player~$j$ plays $s_j^*$ (weakly) increases, then $s_i^*$ is still a best response by player~$i$. 
Loosely speaking, it seems fairly intuitive that a when the other player plays their Nash equilibrium action with larger probability, this will increase a player's incentive to play their best response to that action. However, the following example demonstrates that this intuition does not extend to larger games. 

\begin{example}\label{Example_lemma_1} Consider the $3\times 3$ coordination game 
%\centering
$$\begin{tabular}{cc|c|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player 2} & \multicolumn{1}{c}{}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$b_1$}  & \multicolumn{1}{c}{$b_2$} & \multicolumn{1}{c}{$b_3$}\\\cline{3-5}
      \multirow{3}*{Player 1}  & $a_1$ & ${1,1}$ & $0,0$ & $0,0$ \\\cline{3-5}
      & $a_2$ & $0,0$ & ${2,2}$ & $-3,-3$ \\\cline{3-5}
       & $a_3$ & $0,0$ & $-3,-3$ & ${2,2}$ \\\cline{3-5}
    \end{tabular}
$$

\medskip
\noindent

Suppose that $t > m \geq k=2$, $R_1^t = \{b_3, b_2\}$ and $R_2^t = \{a_2, a_3\}$. Given the distribution of the sampled actions of player~2 in~$R_1^t$, player 1 has an expected payoff of $0$ if they play $a_1$, $-\frac{1}{2}$ if they play $a_2$, and $-\frac{1}{2}$ if they play $a_3$, so that $BR_1(R_1^t)=\{a_1\}$. Given the distribution of the sampled actions of player~1 in~$R_2^t$, player~2 has an expected payoff of $0$ if they play $b_1$, $-\frac{1}{2}$ if they play $b_2$, and $-\frac{1}{2}$ if they play $b_3$, so that $BR_2(R_2^t)=\{b_1\}$. 
Thus, the strict Nash equilibrium $(a_1, b_1)$ is played with positive probability period~$t$.

Let $s(t) = (a_1, b_1)$ and suppose that in period $t+1$ both players sample the record played in period $t$. 
Assuming that player~1 draws the record $s_2(t)=b_1$ instead of one of the two records $b_2$ or $b_3$ drawn in $R_1^t$, there are two possibilities, namely $R_1^{t+1}=\{b_1,b_2\}$ and $R_1^{t+1}=\{b_1,b_3\}$. Because $BR_1(\{b_1,b_2\})=\{a_2\}$ and $BR_1(\{b_1,b_3\})=\{a_3\}$, it is no longer a best response for player~1 to play~$b_1$ if they replace any of the records that they sampled at time~$t$ with the record of player~2 playing $b_1$ at time~$t$. 
%
It is thus possible that adaptive play leads players away from the strict Nash equilibrium $(a_1,b_1)$ after a period in which that strategy profile is played by the two players. 
\end{example}



While Example~\ref{Example_lemma_1} demonstrates that the proof that we provided of Lemma~\ref{Lemma_1} is not valid for coordination games in which players have more than 2 actions, the following example demonstrates that when information is complete ($k=m$), the statement of the lemma is not necessarily true for such games.  

\begin{example}\label{Example2_lemma_1} 
Consider the game in Example~\ref{Example_lemma_1} and let $k = m = 2$. Consider a period 
$t > 2$ such that  $h(t\mid m) = \big((a_2, b_3), (a_3, b_2)\big)$. Because information is complete, $R_1^{t+1} = \{b_2, b_3\}$ and $R_2^{t+1} = \{a_2, a_3\}$. 
Because $BR_1(\{b_2, b_3\})=\{a_1\}$ and $BR_2(\{a_2, a_3\})=\{b_1\}$, necessarily $s(t+1) = (a_1, b_1)$. 
%
Thus, $h(t+1\mid m) = \big((a_3, b_2), (a_1, b_1)\big)$, $R_1^{t+2} = \{b_1, b_2\}$, and $R_2^{t+2} = \{a_1, a_3\}$. 
Therefore, $BR_1(R_1^{t+2})=\{a_2\}$ and $BR_2(R_2^{t+2})=\{b_3\}$, and necessarily $s(t+2) = (a_2, b_3)$. 
%
It follows that in period $t+3$, the players see the history $h(t+2\mid m) = \big((a_1,b_1),(a_2, b_3)\big)$, 
so that $R_1^{t+3} = \{b_1, b_3\}$ and $R_2^{t+3} = \{a_1, a_2\}$, and the players' best responses are $BR_1(R_1^{t+3})=\{a_3\}$ and $BR_2(R_1^{t+3})=\{b_2\}$. 
%
After playing $s(t+3) = (a_3, b_2)$, the history of the last $m$ plays is $h(t+3\mid m) = \big((a_2, b_3), (a_3, b_2)\big)$ and the adaptive play process has thus returned to the same state it was in during period $t$. 

We have demonstrated that adaptive play with memory size $2$ and complete information (sample size 2) will keep cycling from $(a_2, b_3)$ to $(a_3, b_2)$ to $(a_1, b_1)$, to $(a_2, b_3)$, to  $(a_3, b_2)$, and so on.  
%
Thus, although the strict Nash equilibrium: $(a_1, b_1)$ is played every third period as part of this sequence, the process never reaches the convention of playing $(a_1, b_1)$. 
\end{example}



\begin{theorem}\label{Theorem_1}
Let G be a 2$\times$2 coordination game with Nash equilibria $(a_1,b_1)$ and $(a_2,b_2)$,  
in which at least one of the two Nash equilibria is strict (i.e., either $u_1(a_1,b_1) > u_1(a_2,b_1)$ and $u_2(a_1,b_1) > u_2(a_1,b_2)$, or $u_1(a_2,b_2) > u_1(a_1,b_2)$ and $u_2(a_2,b_2) > u_2(a_2,b_1)$). 
%
From any initial state, unperturbed adaptive play with memory size $m$ and sample size $k < m$ converges with probability one to a convention corresponding to a strict Nash equilibrium and locks in.
\end{theorem}


\textbf{Proof of Theorem~\ref{Theorem_1}.}
In light of Lemma~\ref{Lemma_1}, it suffices to demonstrate that there exists a period $t > m$ in which a strict Nash equilibrium $s^*=(s_1^*,s_2^*)$ is played with positive probability, because then the convention of playing $s^*$ can be reached with positive probability, and once that convention is reached, the players will keep playing $s^*$ indefinitely.

Without loss of generality, assume that the Nash equilibrium $(a_1,b_1)$ is strict. 
%
Consider unperturbed adaptive play with memory size $m$ and sample size $k < m$ starting from an arbitrary initial state. Consider an arbitrary period $t>m$ and the history $h(t) = (s(1), s(2), s(3), ..., s(t))$ of plays up to and including time $t$. 
%
We distinguish three cases.

{\bf Case 1. } In period $t+1$ it is possible for the players to draw samples $R_i^{t+1}$, $i=1,2$, such that $a_1\in BR_1(R_1^{t+1})$ and $b_1\in BR_2(R_2^{t+1})$. Then there is a positive probability that $s(t+1)=(a_1,b_1)$. 
%then Lemma~\ref{Lemma_1} establishes that the convention of playing the strict Nash equilibrium $(a_1,b_1)$ can be reached with positive probability, and then the process is locked in.

{\bf Case 2. } In period $t+1$ it is possible for the players to draw samples $R_i^{t+1}$, $i=1,2$, such that $a_2\in BR_1(R_1^{t+1})$ and $b_2\in BR_2(R_2^{t+1})$. There is a positive probability that $s(t+1)=(a_2,b_2)$. If the Nash equilibrium $(a_2,b_2)$ is strict, then we have reached a period in which the players play a strict Nash equilibrium.  
%

If the Nash equilibrium $(a_2,b_2)$ is not strict, then $u_1(a_2,b_2) = u_1(a_1,b_2)$ or $u_2(a_2,b_2) = u_2(a_2,b_1)$ (or both). Assume, without loss of generality, that $u_1(a_2,b_2) = u_1(a_1,b_2)$ (and $u_2(a_2,b_2) \geq u_2(a_2,b_1)$). Then $BR_1(R_1^{t+1})=\{a_1,a_2\}$ and thus $a_1\in BR_1(R_1^{t+1})$. Thus, $s(t+1)=(a_1,b_2)$ is played with positive probability in the adaptive play process. For the next $k-1$ periods, regardless of the actions that player 2 plays and the samples that player 1 draws, player 1 can keep playing $s_1(\hat{t})=a_1$, $\hat{t}=t+2, \ldots, t+k$, as a best response. Then in period $t+k+1$, player 2 can draw a sample $R_2^{t+k+1}$ from player 1's actions that consists of $k$ instances of player 1 playing $a_1$, so that $b_1\in BR_2(R_2^{t+k+1})$. Thus, there is a positive probability that $s(t+k+1)=(a_1,b_1)$. 
%Lemma~\ref{Lemma_1} now establishes that the convention of playing the strict Nash equilibrium $(a_1,b_1)$ can be reached with positive probability, and then the process is locked in.

{\bf Case 3.} If in period $t+1$ it is not possible for the players to draw samples $R_i^{t+1}$, $i=1,2$, such that $s_i\in BR_i(R_i^{t+1})$ for $i=1,2$ and $(s_1,s_2)$ is a Nash equilibrium of $G$, then, without loss of generality, assume that $BR_1(R_1^{t+1})=\{a_1\}$ for all samples that player 1 can draw, and $BR_2(R_2^{t+1})=\{b_2\}$ for all samples that player 2 can draw, so that $s(t+1)=(a_1,b_2)$. 
%

This implies that in $h(t\mid m)$ player 2 played $b_2$ at most $\beta_2$ times, where $\beta_2$ is the largest number in $\{ 0,1,\ldots, k-1\}$ that is strictly lower than $(1-\alpha_2)\times k$.\footnote{We remind the reader that $\alpha_2$ is the probability such that action $a_1$ is a best response by player~$1$ to a mixed strategy $p_2$ of player~$2$ if and only if 
$p_2(b_1) \geq \alpha_2$. Also, because $(a_1,b_1)$ is a strict Nash equilibrium, $\alpha_2 < 1$, so that $(1-\alpha_2)\times k > 0$.}
Similarly, in $h(t\mid m)$ player 1 played $a_1$ at most $\beta_1$ times, where $\beta_1$ is the largest number in $\{ 0, 1,\ldots, k-1\}$ that is strictly lower than $\alpha_1\times k$.\footnote{We remind the reader that $\alpha_1$ is the probability such that action $b_1$ is a best response by player~$2$ to a mixed strategy $p_1$ of player~$1$ if and only if 
$p_1(a_1) \geq \alpha_1$. Note that $\alpha_1 > 0$, because otherwise $b_1\in BR_2(R_2^{t+1})$ regardless of the sample that player 2 draws.} 
However, $s(t+1)=(a_1,b_2)$, so that the number of times that player 1 (resp. 2) plays action $a_1$ (resp. $b_2$) in $h(t+1\mid m)$ is either equal to that in $h(t\mid m)$ (in case $s_1(t-m+1)=a_1$, resp. $s_2(t-m+1)=b_2$) or one higher. 
As long as these numbers do not exceed $\beta_1$, resp. $\beta_2$, the players will keep playing $s(\hat{t})=(a_1,b_2)$ in periods $\hat{t} \geq t+2$. This clearly cannot persist because after $m$ periods the players would only have plays $(a_1,b_2)$ in recent memory. 
%

Let $\hat{t}\geq t+1$ be the first period in which either player 1 played $a_1$ more than $\beta_1$ times in $h(\hat{t}\mid m)$ or player 2 played $b_2$ more than $\beta_2$ times in $h(\hat{t}\mid m)$ (or both). %
Without loss of generality, assume that player 1 played $\beta_1$ instances of $a_1$ in $h(\hat{t}-1\mid m)$ and $\beta_1+1$ instances of $a_1$ in $h(\hat{t}\mid m)$. 
%Thus, $s_1(\hat{t})=a_1$ and $s_1(\hat{t}-m)=a_2$. 
%
Then in period $\hat{t}+1$, player 2 can draw a sample $R_2^{\hat{t}+1}$ that contains $\beta_1+1$ instances of player 1 playing $a_1$, and play $s_2(\hat{t}+1)=b_1\in BR_2(R_2^{\hat{t}+1})$. 
%
Also, player 2 played at most $\beta_2$ instances of $b_2$ in $h(\hat{t}-1\mid m)$), and thus at most $\beta_2+1$ instances of $b_2$ in $h(\hat{t}\mid m)$). Thus, because $k<m$, in period $\hat{t}+1$, player 1 can draw a sample $R_1^{\hat{t}+1}$ that contains no more than $\beta_2$ instances of player 2 playing $b_2$, and play $s_1(\hat{t}+1)=a_1\in BR_1(R_1^{\hat{t}+1})$. 
%
Thus, there is a positive probability that $s(\hat{t}+1)=(a_1,b_1)$. 
%Lemma~\ref{Lemma_1} now establishes that the convention of playing the strict Nash equilibrium $(a_1,b_1)$ can be reached with positive probability, and then the process is locked in.

{\bf Conclusion.} The three cases we considered are exhaustive and thus we have shown that, starting  from any period $t>m$ and with any history of play at that time, we can find a period in which there is a positive probability that the players play a strict Nash equilibrium in the adaptive play process with sample size $k<m$. Lemma~\ref{Lemma_1} then establishes that the convention of playing that strict Nash equilibrium can be reached with positive probability, and then the process is locked in.
$\blacksquare$

\medskip
Note that in the proof of Theorem~\ref{Theorem_1}, there is only one instance in which we use that information is incomplete ($k<m$), and that is in Case 3, where we need it to guarantee that it cannot be the case that the adaptive play process can get "stuck" in a situation where both players mis-coordinate in every period, oscillating between $(a_1,b_2)$ and $(a_2,b_1)$ and necessarily switching actions in exactly the same periods. 
%
If the game and sample sizes are such that this cannot happen anyway, then we do not need information to be incomplete at all, and we can have $k=m$. 
We use the notation $\lceil\cdot\rceil$ to denote the rounding up of any real number to the smallest natural number that is at least as large.\footnote{So, if $n$ is a natural number itself, then $\lceil n\rceil=n$. Also, we include $0$ in the set of natural numbers.}





\begin{theorem}\label{Theorem_2}
Let G be a 2$\times$2 coordination game with Nash equilibria $(a_1,b_1)$ and $(a_2,b_2)$,  
in which at least one of the two Nash equilibria is strict (i.e., either $u_1(a_1,b_1) > u_1(a_2,b_1)$ and $u_2(a_1,b_1) > u_2(a_1,b_2)$, or $u_1(a_2,b_2) > u_1(a_1,b_2)$ and $u_2(a_2,b_2) > u_2(a_2,b_1)$)  
%
and such that $\alpha_1\neq 1-\alpha_2$.\footnote{Thus, the smallest probability for player~1 to play $a_1$ such that action $b_1$ is a best response by player~$2$ is not equal to the smallest probability for player~2 to play $b_2$ such that action $a_2$ is a best response by player~$1$.} 
%
Let the sample size $k$ be such that $\lceil\alpha_1\times k\rceil \neq \lceil (1-\alpha_2)\times k\rceil$.\footnote{Note that if the game $G$ is such that $\alpha_1$ and $1-\alpha_2$ are close, then this will require a large sample size.}
From any initial state, unperturbed adaptive play with memory size $m$ and sample size $k \leq m$ converges with probability one to a convention corresponding to a strict Nash equilibrium and locks in.
\end{theorem}


\textbf{Proof of Theorem~\ref{Theorem_2}.}
If $k<m$, then Theorem~\ref{Theorem_1} applies. So, suppose that $k=m$, i.e, information is complete in the sense that players see \emph{all} of the past $m$ records.  

Consider an adaptive play process with $k=m$. If in some period $t>m$ the players coordinate, i.e., $s(t)=(a_1,b_1)$ or $s(t)=(a_2,b_2)$, then we can apply cases 1 or 2 in the proof of Theorem~\ref{Theorem_1} to establish that there is a positive probability that the players play a strict Nash equilibrium (note that these cases do not depend on $k < m$). 
Lemma~\ref{Lemma_1} then establishes that the convention of playing that strict Nash equilibrium can be reached with positive probability, and then the process is locked in.

Thus, it remains to consider the possibility that the players mis-coordinate in all periods, i.e., $s(t)\in \{(a_1,b_2),(a_2,b_1)\}$ for all $t$. We will demonstrate that this cannot happen because $\lceil \alpha_1\times m\rceil \neq\lceil (1-\alpha_2)\times m\rceil$ implies that an adaptive play process with $k=m$ cannot result in string of mis-coordinated plays $s(1),s(2), \ldots $ with $s(t)\in \{(a_1,b_2),(a_2,b_1)\}$ for all $t$. 
%

If, in some period $t>m$,\footnote{We consider only periods $t>m$ to ensure that the players have $m$ periods' plays available in memory.} 
 the players observe a history of play that consists of a string of $m$ instances of $(a_1,b_2)$ having been played in the previous $m$ periods, player~2's unique best response is to play~$b_1$ in the next period or player~1's unique best response is to play~$a_2$ in the next period.\footnote{This uses $\lceil \alpha_1\times m\rceil \neq\lceil (1-\alpha_2)\times m\rceil$, which implies that it cannot be the case that player 1 can best respond by playing~$a_1$ \emph{and} player 2 can best respond by playing~$b_2$ after both observe $m$ instances of $(a_1,b_2)$ having been played.} 
%
Thus, any string of mis-coordinated plays that contains a string of more than $m$ subsequent plays of $(a_1,b_2)$ cannot be the result of an adaptive play process. 
%
Similarly, any string of mis-coordinated plays that contains a string of more than $m$ subsequent plays of $(a_2,b_1)$ cannot be the result of an adaptive play process. 
%
We conclude that if the players mis-coordinate in all periods, and they follow an adaptive play process, then the process needs to switch repeatedly between playing $(a_1,b_2)$ and $(a_2,b_1)$. 
%

%For player 1 to switch to playing $a_1$, they need to observe $\lceil \alpha_2\times m\rceil$ instances of player~2 playing $b_1$, and for player 2 to switch to playing $b_2$, they need to observe $\lceil (1-\alpha_1)\times m\rceil$ instances of player~1 playing $a_2$.

For player 1 to switch to playing $a_2$, they need to observe $\lceil (1-\alpha_2)\times m\rceil$ instances of player~2 playing $b_2$, and for player 2 to switch to playing $b_1$, they need to observe $\lceil \alpha_1\times m\rceil$ instances of player~1 playing $a_1$.
%
However, in all periods $t>m$, because $k=m$, player~1 samples as many records of player~2 playing $b_2$ as player~2 samples records of player~1 playing $a_1$. 
Thus, $\lceil \alpha_1\times m\rceil \neq\lceil (1-\alpha_2)\times m\rceil$ implies that the players will not switch from playing $(a_1,b_2)$ to playing $(a_2,b_1)$ in the same period when they follow an adaptive play process.    
%
$\blacksquare$

\newpage

%Allowing $k > m/2$ can change the resistance between conventions. For example, consider the transition from the convention of $(a_1, b_1)$ to $(a_2, b_2)$. To transition, the best response of both players must change. In order for $(a_2, b_2)$ to be the best response profile, player 1 must have played $a_2$ at least $\lceil \beta k \rceil$ times and player 2 must have played $b_2$ at least $\lceil \alpha k \rceil$ times in the memory. If $\lceil \alpha k \rceil + \lceil \beta k \rceil \leq m$ and if $\alpha < \beta$ then player 2 can make the initial $\lceil \alpha k \rceil$ mistakes playing $b_2$ followed by player 1 sampling every period player 2 played $b_2$ for $\lceil \beta k \rceil$ periods in a row, playing $a_2$ as a best response each time. If instead $\beta < \alpha$ then player 1 can make the initial $\lceil \alpha k \rceil$ mistakes playing $a_2$ followed by player 2 sampling every period player 1 played $a_2$ for $\lceil \beta k \rceil$ periods in a row, playing $b_2$ as a best response each time. At this point since $\lceil \alpha k \rceil + \lceil \beta k \rceil \leq m$ it is possible for the players to sample $b_2$ and $a_2$ as much as required make $a_2$ and $b_2$ best responses for players 1 and 2 respectively for all future periods. Note that when $k \leq m/2$, the condition $\lceil \alpha k \rceil + \lceil \beta k \rceil \leq m$ is always true which is why the resistance from $(a_1, b_1)$ to $(a_2, b_2)$ would be calculated as $\min(\lceil \alpha k \rceil, \lceil \beta k \rceil)$.

%However, if $k > m/2$, it may be the case that $\lceil \alpha k \rceil + \lceil \beta k \rceil > m$. In which case the mistakes made by the player who started the transition (deviator) would start to fall out of memory before the other player (responder) is able to play enough $a_2$ or $b_2$ to make playing $b_2$ or $a_2$ the best response for the deviator. To correct for this most efficiently, additional perturbations must be made such that $\lceil \alpha k \rceil$ plays of $b_2$ and $\lceil \beta k \rceil$ plays of $a_2$ fit inside the memory requiring an overlap of $\lceil \alpha k \rceil+\lceil \beta k \rceil-m$ additional perturbations.

%As result, the resistance from  $(a_1, b_1)$ to $(a_2, b_2)$ can be generalized for any $k \leq m$ as $r^{k,m}_{1,2}=\min(\lceil \alpha k \rceil,\lceil \beta k \rceil)+\max(\lceil \alpha k \rceil+\lceil \beta k \rceil-m,0)$. A similar calculation shows that the resistance from $(a_2, b_2)$ to $(a_1, b_1)$ is $r^{k,m}_{2,1}=\min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil)+\max(\lceil (1-\alpha) k \rceil+\lceil (1-\beta) k \rceil-m,0)$.

%This change in pairwise resistance begs the question: does the change have any effect on stochastic stability? We prove that for all $m > k$ that the pairwise resistance relationship remains unchanged.

%Consider the pairwise resistances between $(a_1, b_1)$ and $(a_2, b_2)$ as discussed above. Without loss of generality assume $r^{k,m}_{1,2} < r^{k,m}_{2,1}$ for $m \geq 2k$. We will show that when $m < 2k$, the inequality $r^{k,m}_{1,2} < r^{k,m}_{2,1}$ is maintained. $k \leq m/2$, and $r^{k,m}_{1,2} < r^{k,m}_{2,1}$ means that $\min(\lceil \alpha k \rceil,\lceil \beta k \rceil) < \min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil)$. Without loss of generality assume $\alpha \geq \beta$. So, $\min(\lceil \alpha k \rceil,\lceil \beta k \rceil) = \lceil \beta k \rceil$ and $\min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil) = \lceil (1-\alpha) k \rceil$ which means $\lceil \beta k \rceil < \lceil (1-\alpha) k \rceil$. It follows that $\beta < 1- \alpha$ which means $\alpha < 1 - \beta$ so $\lceil \alpha k \rceil \leq \lceil (1 - \beta) k \rceil$. Combining $\lceil \beta k \rceil < \lceil (1-\alpha) k \rceil$ and  $\lceil \alpha k \rceil \leq \lceil (1 - \beta) k \rceil$ we get $\lceil \alpha k \rceil+\lceil \beta k \rceil < \lceil (1-\alpha) k \rceil+\lceil (1-\beta) k \rceil$. So $\min(\lceil \alpha k \rceil,\lceil \beta k \rceil)+\max(\lceil \alpha k \rceil+\lceil \beta k \rceil-m,0) < \min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil)+\max(\lceil (1-\alpha) k \rceil+\lceil (1-\beta) k \rceil-m,0)$ which means $r^{k,m}_{1,2} < r^{k,m}_{2,1}$. So we have shown that pairwise resistance inequalities remain unchanged by $m$. 

%Now assume $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ for $m \geq 2k$. We will show that when $k < m < 2k$, the equality $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ is maintained. $k \leq m/2$, and $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ implies that $\min(\lceil \alpha k \rceil,\lceil \beta k \rceil) = \min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil)$. Without loss of generality assume $\alpha \geq \beta$. So, $\min(\lceil \alpha k \rceil,\lceil \beta k \rceil) = \lceil \beta k \rceil$ and $\min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil) = \lceil (1-\alpha) k \rceil$ which means $\lceil \beta k \rceil = \lceil (1-\alpha) k \rceil$. It is easily verified that $\lceil \alpha k \rceil+\lceil (1-\alpha) k \rceil \in (k, k+1)$. Which means $\lceil \alpha k \rceil+\lceil \beta k \rceil \leq k+1$. Since $k+1 \leq m$, it follows that $\max(\lceil \alpha k \rceil+\lceil \beta k \rceil-m,0) = 0$. Similar logic can be used to show $\max(\lceil (1-\alpha) k \rceil+\lceil (1-\beta) k \rceil-m,0) = 0$. Those results combined with the assumption $\min(\lceil \alpha k \rceil,\lceil \beta k \rceil) = \min(\lceil (1-\alpha) k \rceil,\lceil (1-\beta) k \rceil)$ mean that $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ when $k < m < 2k$. So we have shown that all pairwise resistance relationships remain unchanged for all $m > k$. As result, the stochastically stable state remains unchanged in 2x2 games.

\section{Perturbed adaptive play in $2 \times 2$ games}

Now consider the adaptive play process as modeled in Section 2 but where players have a small probability of playing an action that is not their best response. Specifically, in every round players now play a strategy at random with probability $\varepsilon$ and with probability $1-\varepsilon$ they play a best response to their drawn sample, $R_i^{t}$. As such, an action that is not in the set of possible best responses to samples drawn from the memory can be played with probability $\varepsilon/2$. We shall refer to such actions as \textit{mistakes}. This process is called perturbed adaptive play. Allowing for mistakes makes transitions possible between conventions even those where strict Nash equilibria are played. Continuing with the setup established in Section 2 where $(a_1, b_1)$ and $(a_2, b_2)$ are Nash equilibria, denote the convention of $(a_i, b_i)$ as $h_i$ as $m$ periods of $(a_i, b_i)$.
Now consider the transition from $h_i$ to $h_j$. Let the resistance, $r_{i,j}^{k,m}$, be the minimum number of mistakes necessary to make the transition from $h_i$ to $h_j$ in the perturbed adaptive play process.
\cite{Young1998} shows that when $k \leq m/2$ that the resistance between conventions is independent of $m$. From $h_2$ to $h_1$ the resistance is calculated as $\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil)$ and from $h_1$ to $h_2$ the resistance is calculated as 
$\min(\lceil (1-\alpha) \times k \rceil,\lceil (1-\alpha_2) \times  k \rceil)$. We show that the resistance may increase and depends on $m$ when $k > m/2$.


\begin{theorem}\label{Theorem_3}
Let G be a 2$\times$2 coordination game with Nash equilibria $(a_1,b_1)$ and $(a_2,b_2)$. For all $k \leq m$ the resistance from $h_2$ to $h_1$ depends on $m$ and is calculated by $r_{2,1}^{k,m} = \min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil)+\max(\lceil~\alpha_1~\times~k~\rceil+\lceil \alpha_2 \times k \rceil-m,0)$. Likewise, the resistance from $h_1$ to $h_2$ is $r^{k,m}_{1,2}=\min(\lceil (1-\alpha) \times k \rceil, \lceil (1-\alpha_2) \times  k \rceil)+\max(\lceil (1-\alpha) \times k \rceil+\lceil (1-\alpha_2) \times k \rceil-m,0)$.
\end{theorem}


\textbf{Proof of Theorem~\ref{Theorem_3}.}


Consider the transition from $h_2$ to $h_1$. To transition to $h_1$, Lemma~\ref{Lemma_1} implies that it is sufficient to reach a period where $a_1$ and $b_1$ are simultaneously best responses to sampled play. For such conditions to be met in some period $T$, player~1 must have played $a_1$ at least $\lceil \alpha_1 \times k \rceil$ times and player~2 must have played $b_1$ at least $\lceil \alpha_2 \times k \rceil$ times between period $T-m$ and period $T-1$. Since initially the state is $h_2$, $a_1$ or $b_1$ can only be played by mistake until enough $b_1$ or $a_1$ has been played to make $a_1$ or $b_1$ a best response. Without loss of generality assume $\alpha_1 \leq \alpha_2$. It follows that it will take no more plays of $a_1$ to make $b_1$ a best response for player~2 than it will take plays of $b_1$ to make $a_1$ a best response for player~1. As such, a path of the least necessary mistakes from $h_2$ to $h_1$ involves player~1 making mistakes playing $a_1$ until player~2 can play $b_1$ as a best response. Furthermore, since memory is limited, the necessary mistakes made by player~1 should be consecutive to prevent the mistakes from falling out of memory before player~1 can replace those mistakes with best responses of $a_1$. Now let $h(t|m) = h_2$ and consider the following two cases:
%
%The following argument is similar to that made in \cite{Young1998}. If $(a_2, b_2)$ is a strict Nash equilibria then mistakes must be made in order to change one of the players best responses. Player~1's best response will change if they sample at least $\lceil \alpha_2 \times k \rceil$ periods in which player~2 played $b_1$. Likewise, Player~2's best response will change if they sample at least $\lceil \alpha_1 \times k \rceil$ periods in which player~1 played $a_1$. Without loss of generality assume that $\alpha_1 \leq \alpha_2$. If $k \leq m/2$, then $\lceil \alpha_1 \times k \rceil$ consecutive mistakes can be made by player~1 playing $a_1$ each round. At this point, player~2 can for $k$ rounds sample the $\lceil \alpha_1 \times k \rceil$ records of player~1 playing $a_1$ and play $b_1$ as a best response. Player~1 can then for $k$ rounds sample the $k \geq \lceil \alpha_2 \times k \rceil$ records of player~2 playing $b_1$. Since $k \leq m/2$ then there exists $k$ records of both $a_1$ and $b_1$ in the most recent $m$ history of play which means both plays can draw a sample such that $a_1$ and $b_1$ are best responses for player~1 and player~2 respectively. At which point, Lemma \ref{Lemma_1} can be applied and there is a positive probability that a convention of playing $(a_1, b_1)$ can be reached. As such, the least number of mistakes that need be made to transition from $h_2$ to $h_1$ is $\min(\lceil \alpha_1 k \rceil, \lceil \alpha_2 k \rceil)$.

{\bf Case 1.} If $\lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil \leq m$ then our proof is similar to that shown in \cite{Young1998}. Starting in period $t+1$, player~1 can make $\lceil \alpha_1 \times k \rceil$ consecutive mistakes playing $a_1$ in each period. During each of these periods, player~2 can sample no more than $\lceil \alpha_1 \times k \rceil - 1$ plays of $a_1$ so without making mistakes, they must play $b_2$ as a best response.

In periods $t+\lceil \alpha_1 \times k \rceil + 1$ to $t + \lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil$, player~2 can now sample every $a_1$ player~1 played in periods $t+1$ to $t+\lceil \alpha_1 \times k \rceil$. By doing so, player~2 can play $b_1$ as a best response in every period. Meanwhile, player~1 can sample no more than $\lceil \alpha_2 \times k \rceil - 1$ plays of $b_1$ in these periods. So without making mistakes, they must play $a_2$ as a best response.


\begin{table}[htbp]
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{|c|*{11}{c|}}
\hline
& \multicolumn{11}{|c|}{Play} \\
\hline
Round \# & $t-m+1$ & $\ldots$ & $t$ & $t+1$ & $\ldots$ & $t+\lceil\alpha_1\times k\rceil$ & $t+\lceil\alpha_1\times k\rceil+1$ & $\ldots$ & $t+\lceil\alpha_1\times k\rceil+\lceil\alpha_2\times k\rceil$ & $t+\lceil\alpha_1\times k\rceil+\lceil\alpha_2\times k\rceil+1$ & $\ldots$ \\
\hline
Player 1 & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_1$} & \textcolor{blue}{$a_1$} \\
\hline
Player 2 & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} \\
\hline
\end{tabular}%
}
\small
The color red denotes actions which must be mistakes. Actions colored blue can be played as a best response.
\end{table}


In period $t + \lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil + 1$ since $\lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil \leq m$ it is possible for player~2 to sample the sequential periods from $t + 1$ to $t + \lceil \alpha_1 \times k \rceil$ in which player~1 played $a_1$ each time while player~1 samples all periods from $t+\lceil \alpha_2 \times k \rceil + 1$ to $t + \lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil$. So $b_1$ gets sampled at least $\lceil \alpha_2 \times k \rceil$ times and $a_1$ gets sampled at least $\lceil \alpha_1 \times k \rceil$ times making $a_1$ and $b_1$ simultaneously best responses for player 1 and player 2 respectively. Thus, Lemma \ref{Lemma_1} applies and $h_1$ can be reached with no further mistakes. 

Clearly no transition from $h_2$ to $h_1$ can be accomplished with fewer mistakes than those in the process described since without $\lceil \alpha_1 \times k \rceil$ mistakes there will not be enough $b_1$ or $a_1$ in the memory to make $a_1$ or $b_1$ a best response. 

Note that when $k \leq m/2$, the condition $\lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil \leq m$ is always true which is why the resistance from $h_2$ to $h_1$ would be calculated as $r_{2,1}^{k} = \min(\lceil \alpha_1 \times k \rceil, \lceil \alpha_2 \times k \rceil)$ as in \cite{Young1998}. However, if $k > m/2$, this calculation does not always hold. 




{\bf Case 2.} If $\lceil \alpha_1 \times k \rceil + \lceil \alpha_2 \times k \rceil > m$ then in order for the transition to be made from $h_2$ to $h_1$, perturbations beyond the minimum required to change the best response of one player must be made to achieve the condition that $\lceil \alpha_1 \times k \rceil$ plays of $b_1$ and $\lceil \alpha_2 \times k \rceil$ plays of $a_1$ occur within $m$ periods. In order to achieve this condition, $a_1$ and $b_1$ must be played concurrently for a minimum of $l:= \lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil-m$ periods. As such, either $b_1$ must be made as a mistake $l$ times before player~2 plays $b_1$ as a best response or $a_1$ must be played as a mistake during the periods where player~2 is playing $b_1$ as a best response. I describe one such path:

Starting in period $t+1$, player~1 can make $\lceil \alpha_1 \times k \rceil$ consecutive mistakes playing $a_1$ in each period. During periods $t+1$ to $t+m-\lceil \alpha_2 \times k \rceil$, player~2 can sample no more than $\lceil \alpha_1 \times k \rceil - 1$ plays of $a_1$ so without making mistakes, they must play $b_2$ as a best response. During periods $t+m+1-\lceil \alpha_2 \times k \rceil$ to $t+\lceil \alpha_1 \times k \rceil$ player~2 can make $\mu$ mistakes playing $b_1$. 


\begin{table}[htbp]
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{|c|*{14}{c|}}
\hline
& \multicolumn{14}{|c|}{Play} \\
\hline
Round \# & $t-m+1$ & $\ldots$ & $t$ & $t+1$ & $\ldots$ & $t+m-\lceil\alpha_2\times k\rceil$ & $t+m+1-\lceil\alpha_2\times k\rceil$ & $\ldots$ & $t+\lceil\alpha_1\times k\rceil$ & $t+\lceil\alpha_1\times k\rceil+1$ & $\ldots$ & $t+\lceil\alpha_1\times k\rceil+\lceil\alpha_2\times k\rceil$ & $t+\lceil\alpha_1\times k\rceil+\lceil\alpha_2\times k\rceil+1$ & $\ldots$ \\
\hline
Player 1 & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{red}{$a_1$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_2$} & \textcolor{blue}{$a_1$} & \textcolor{blue}{$a_1$} \\
\hline
Player 2 & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{blue}{$b_2$} & \textcolor{red}{$b_1$} & \textcolor{red}{$b_1$} & \textcolor{red}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} & \textcolor{blue}{$b_1$} \\
\hline
\end{tabular}%
}
\small
The color red denotes actions which must be mistakes. Actions colored blue can be played as a best response.
\end{table}


In periods $t+\lceil \alpha_1 \times k \rceil + 1$ to $t + m$, player~2 can now sample every $a_1$ player~1 played in periods $t+1$ to $t+\lceil \alpha_1 \times k \rceil$. By doing so, player~2 can play $b_1$ as a best response in every period. Meanwhile, player~1 can sample no more than $\lceil \alpha_2 \times k \rceil - 1$ plays of $b_1$ in these periods. So without making mistakes, they must play $a_2$ as a best response.

In period $t + m + 1$ it is possible for player~2 to sample the sequential periods from $t + 1$ to $t + \lceil \alpha_1 \times k \rceil$ in which player~1 played $a_1$ each time while player~1 samples all periods from $t+m+1-\lceil \alpha_2 \times k \rceil$ to $t + m$. So $b_1$ gets sampled at least $\lceil \alpha_2 \times k \rceil$ times and $a_1$ gets sampled at least $\lceil \alpha_1 \times k \rceil$ times making $a_1$ and $b_1$ simultaneously best responses for player 1 and player 2 respectively. Thus, Lemma \ref{Lemma_1} applies and $h_1$ can be reached with no further mistakes. 

As discussed, atleast $\lceil \alpha_1 \times k \rceil$ mistakes are necessary to make one player play $a_1$ or $b_1$ as a best response. In addition, in this case due to the constrained memory size, additional mistakes are needed to make $a_1$ and $b_1$ simultaneous best responses before the initial mistakes start to fade from the memory. Specifically, a minimum of $\mu$ mistakes are required. So, the processess described which contained $\lceil \alpha_1 \times k \rceil + \mu$ mistakes is the minimal necessary to transition from $h_2$ to $h_1$.

So, in this case, the resistance from $h_2$ to $h_1$ is calculated as $r_{2,1}^{k,m} = \min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil)+\lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil-m$ which is greater than the resistance in Case~1.

{\bf Conclusion.} Two complimentary cases were considered which resulted in different resistance calculations. We generalize the resistance from $h_2$ to $h_1$ for all $k \leq m$ as $r^{k,m}_{2,1}=\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil)+\max(\lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil-m,0)$. A similar calculation shows that the resistance from $h_1$ to $h_2$ is $r^{k,m}_{1,2}=\min(\lceil (1-\alpha) \times k \rceil,\lceil (1-\alpha_2) \times  k \rceil)+\max(\lceil (1-\alpha) \times k \rceil+\lceil (1-\alpha_2) \times k \rceil-m,0)$.
$\blacksquare$

Note that these resistance calculations are equivalent to those given by \cite{Young1998} when $k \leq m/2$. However, when $k>m/2$ the resistance may change as additional mistakes may be needed in order for the memory to simultaneously hold enough switched actions for both players. Our formulation of resistance is robust to all $k \leq m$. 


The perturbed adaptive play process as modeled defines an irreducible Markov process which has an associated unique stationary distribution $\mu^\varepsilon$. A state $h(t\mid m)^*$ is stochastically stable if $\lim \limits_{\varepsilon \rightarrow 0} \mu^\varepsilon\big(h(t\mid m)^*\big) > 0$ \cite{young1993evolution}.

Between two conventions, \cite{Young1998} showed that a convention is stochastically stable if and only if the resistance in the transition away from it is atleast as large as the resistance in the transition towards it.
We just showed that pairwise resistance may change with the size of the memory when $2k > m$. This result begs the question: does the change in resistance have any effect on pairwise risk dominance and thus, stochastic stability? We prove that for all $m > k$ that the pairwise resistance relationship remains unchanged.

\begin{theorem}\label{Theorem_4}
Given a fixed $k$, for all $m > k$ that the pairwise resistance relationship between $h_i$ and $h_j$ remains unchanged in $2 \times 2$ games.
\end{theorem}


\textbf{Proof of Theorem~\ref{Theorem_4}.}


Consider the pairwise resistances between $h_2$ and $h_1$. We will consider both the case where the resistance $r_{1,2}^{k,m} \neq r_{2,1}^{k,m}$ and where $r_{1,2}^{k,m} = r_{2,1}^{k,m}$ when $m \geq 2k$. We show that when the resistance does depend on $m$, when $m<2k$, the same relationship between $r_{1,2}^{k,m}$ and $r_{2,1}^{k,m}$ is maintained.

{\bf Case 1.} Assume that $r^{k,m}_{2,1} \neq r^{k,m}_{1,2}$ when $m \geq 2k$. Without loss of generality assume $r^{k,m}_{2,1} < r^{k,m}_{1,2}$ when $m \geq 2k$. We will show that when $m < 2k$, the inequality $r^{k,m}_{2,1} < r^{k,m}_{1,2}$ is maintained. $m \geq 2k$ and $r^{k,m}_{2,1} < r^{k,m}_{1,2}$ means that $\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil) < \min(\lceil (1-\alpha_1) \times k \rceil,\lceil (1-\alpha_2) \times k \rceil)$. Without loss of generality assume $\alpha_1 \geq \alpha_2$. So, $\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil) = \lceil \alpha_2 \times k \rceil$ and $\min(\lceil (1-\alpha_1) \times k \rceil,\lceil (1-\alpha_2) \times k \rceil) = \lceil (1-\alpha_1) \times k \rceil$ which means $\lceil \alpha_2 \times k \rceil < \lceil (1-\alpha_1) \times k \rceil$. It follows that $\alpha_2< 1- \alpha_1$ so $\alpha_1< 1 - \alpha_2$ which means $\lceil \alpha_1 \times k \rceil \leq \lceil (1 - \alpha_2) \times k \rceil$. Combining $\lceil \alpha_2 \times k \rceil < \lceil (1-\alpha_1) \times k \rceil$ and  $\lceil \alpha_1 \times k \rceil \leq \lceil (1 - \alpha_2) \times k \rceil$ we get $\lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil < \lceil (1-\alpha_1) \times k \rceil+\lceil (1-\alpha_2) \times k \rceil$.

Combining that result with the initial condition, it follows that $r^{k,m}_{2,1} = \min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil)+\max(\lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil-m,0) < \min(\lceil (1-\alpha_1) \times k \rceil,\lceil (1-\alpha_2) \times k \rceil)+\max(\lceil (1-\alpha_1) \times k \rceil+\lceil (1-\alpha_2) \times k \rceil-m,0) = r^{k,m}_{1,2}$. So we have shown that pairwise resistance inequalities remain unchanged by $m$ in this case.

{\bf Case 2.} Now assume $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ when $m \geq 2k$. We will show that when $k < m < 2k$, the equality $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ is maintained. $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ when $k \leq m/2$ implies that $\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil) = \min(\lceil (1-\alpha_1) \times k \rceil,\lceil (1-\alpha_2) \times k \rceil)$. Without loss of generality assume $\alpha_1\geq \alpha_2$. So, $\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil) = \lceil \alpha_2 \times k \rceil$ and $\min(\lceil (1-\alpha_1) \times k \rceil,\lceil (1-\alpha_2) \times k \rceil) = \lceil (1-\alpha_1) \times k \rceil$ which means $\lceil \alpha_2 \times k \rceil = \lceil (1-\alpha_1) \times k \rceil$. It is easily verified that $\lceil \alpha_1 \times k \rceil+\lceil (1-\alpha_1) \times k \rceil \in (k, k+1)$ and so $\lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil \leq k+1$. Since $k+1 \leq m$, it follows that $\max(\lceil \alpha_1 \times k \rceil+\lceil \alpha_2 \times k \rceil-m,0) = 0$. Similar logic can be used to show that $\max(\lceil (1-\alpha_1) \times k \rceil+\lceil (1-\alpha_2) \times k \rceil-m,0) = 0$. Those results combined with the assumption $\min(\lceil \alpha_1 \times k \rceil,\lceil \alpha_2 \times k \rceil) = \min(\lceil (1-\alpha_1) \times k \rceil,\lceil (1-\alpha_2) \times k \rceil)$ mean that $r^{k,m}_{1,2} = r^{k,m}_{2,1}$ for all $m > k$ in this case.

{\bf Conclusion.} The two cases are exhaustive. So, we have shown that all pairwise resistance relationships remain unchanged for all $m > k$ given $k$ is fixed.
$\blacksquare$

The result of Theorem~\ref{Theorem_4} imply that the states which are stochastically stable remain unchanged in 2x2 games as a result of the changed resistance when $k<m<2k$.

\begin{example}\label{Example_Theorem_4} Consider the $2\times 2$ coordination game 
%\centering
$$\begin{tabular}{cc|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player 2}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$b_1$}  & \multicolumn{1}{c}{$b_2$} \\\cline{3-4}
      \multirow{2}*{Player 1}  & $a_1$ & ${10,11}$ & $0,0$ \\\cline{3-4}
      & $a_2$ & $0,1$ & ${10,10}$ \\\cline{3-4}
    \end{tabular}
$$

Suppose that $k = 10$ and consider the resistances between $h_1$ and $h_2$. Note that in this game $\alpha_1 = 9/20$ and $\alpha_2 = 1/2$. As such, $\lceil \alpha_1 \times k \rceil = \lceil \alpha_2 \times k \rceil = \lceil (1-\alpha_2) \times k \rceil = 5$ and $\lceil (1-\alpha_2) \times k \rceil = 6$. As result, for all $m > k = 10$ the resistances between $h_1$ and $h_2$ are equal, $r_{1,2}^{k,m} = r_{2,1}^{k,m} = 5$ and as such, both $h_1$ and $h_2$ are stochastically stable. Now consider $m = k = 10$. In this case, the resistance from $h_1$ to $h_2$ increases: $r_{1,2}^{k,m} = 6$ while the resistance from $h_2$ to $h_1$ remains unchanged: $r_{2,1}^{k,m} = 5$. As result, only $h_1$ would be stochastically stable.
\end{example}

Example~\ref{Example_Theorem_4} shows that the value of $m$ can affect which states are stochaistically stable. However, as Case 1 in Theorem~\ref{Theorem_4} shows, this can only occur when the resistances between conventions are equal when $m$ is not a factor in the resistance calculation ($m>2k$). 

\medskip
\noindent


\section{Conclusion}

Young's model of adaptive play has been studied and applied to a wide variety of games. However, the boundary of precisely how incomplete sampling needs to be in order for foundational results like convergence to a convention remain unaddressed. We examined the most foundational game, the $2\times 2$ coordination game, and proved that in this case, \textit{any} degree of incomplete sampling is sufficient for the unperturbed adaptive play process to converge to an equilibrium. In addition, we show that in all but some $2 \times 2$ games that the criterion of incomplete information is unnecessary. We also examine how allowing for larger (than $s<m/s$) games affect the perturbed adaptive process. We identified the function for resistance that is robust to all sample sizes $s \leq m$ and found that increasing the sample size beyond $s/m \leq 1/2$ may result in increased resistance between conventions. However, we also showed that even if the resistance does change due to the relative size of the sample to the memory, that the stochastically stable states remain unchanged if sampling is incomplete $(s<m)$.

\newpage

\bibliographystyle{abbrvnat}
\bibliography{bib.bib}


\end{document}
